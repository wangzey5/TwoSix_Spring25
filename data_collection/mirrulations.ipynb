{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4620689-9517-4b09-88f4-a8c0d3881bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "import tempfile\n",
    "import json\n",
    "import os\n",
    "\n",
    "import boto3\n",
    "from botocore import UNSIGNED, config\n",
    "import pymongo\n",
    "\n",
    "unsigned=config.Config(signature_version=UNSIGNED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95186b2-d738-4d06-b981-e972aa40d894",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource(\"s3\", config=unsigned)\n",
    "bucket = s3.Bucket(\"mirrulations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97b419d-e23d-4e1f-ab90-9dcbb8991c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspired by https://stackoverflow.com/questions/54833895/how-to-get-top-level-folders-in-an-s3-bucket-using-boto3\n",
    "client = boto3.client('s3', config=unsigned)\n",
    "paginator = client.get_paginator('list_objects')\n",
    "result = paginator.paginate(Bucket='mirrulations', Delimiter='/')\n",
    "\n",
    "agencies = [prefix.get(\"Prefix\").rstrip(\"/\") for prefix in result.search('CommonPrefixes') if prefix is not None]\n",
    "dockets = []\n",
    "for i, agency in enumerate(agencies):\n",
    "    print(f\"[{i}/{len(agencies)}]({agency})\", end=\" \"*100 + \"\\r\")\n",
    "    result = paginator.paginate(\n",
    "        Bucket='mirrulations',\n",
    "        Delimiter='/',\n",
    "        Prefix=f\"{agency}/\"\n",
    "    )\n",
    "    dockets.extend([prefix.get(\"Prefix\") for prefix in result.search(\"CommonPrefixes\") if prefix is not None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de10815-7df1-4c40-8285-d181b1b447f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dockets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f97813-6550-4ed6-b8ca-44f26b855c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSubKeys(path, fullKey=True):\n",
    "    if fullKey:\n",
    "        extract = lambda key: key \n",
    "    else:\n",
    "        extract = lambda keystr: keystr.split(\"/\")[-2]\n",
    "    return [extract(prefix[\"Prefix\"]) for prefix in client.list_objects(\n",
    "        Bucket=\"mirrulations\", \n",
    "        Prefix=path,\n",
    "        Delimiter=\"/\"\n",
    "    )[\"CommonPrefixes\"]]\n",
    "\n",
    "def getFileKeys(path):\n",
    "    return [metadata[\"Key\"] for metadata in client.list_objects(\n",
    "        Bucket=\"mirrulations\", \n",
    "        Prefix=path,\n",
    "        Delimiter=\"/\"\n",
    "    )[\"Contents\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e942c0c-d947-4c3b-b324-83f2646198a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getContents(base_path, subkey):\n",
    "    path = base_path + f\"{subkey}/\"\n",
    "    keys = getFileKeys(path)\n",
    "    return keys\n",
    "\n",
    "def getSubContents(base_path, subkey):\n",
    "    path = base_path + f\"{subkey}/\"\n",
    "    keys = []\n",
    "    for key in getSubKeys(path, fullKey=True):\n",
    "        keys.extend(getFileKeys(key))\n",
    "    return keys\n",
    "\n",
    "getFileName = lambda path: path.split(\"/\")[-1].split(\".\")[0]\n",
    "def getFileData(paths, dataExtractor=lambda file: json.load(file)):\n",
    "    data = {getFileName(path).split(\"_\")[0]: [] for path in paths} # init with []\n",
    "    temp = tempfile.NamedTemporaryFile(delete=False, delete_on_close=False)\n",
    "    for path in paths:\n",
    "        bucket.download_file(path, temp.name)\n",
    "        with open(temp.name, \"r\") as file:\n",
    "            comment_key = getFileName(path).split(\"_\")[0]\n",
    "            data[comment_key].append(dataExtractor(file))\n",
    "\n",
    "    os.remove(temp.name)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484f8a4b-35bf-47c6-a718-12d81aa9e754",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addUpdate(dict_, key, val):\n",
    "    if key not in dict_:\n",
    "        dict_[key] = {}\n",
    "    dict_[key].update(val)\n",
    "    \n",
    "def updateJson(dict_, base_path, key):\n",
    "    paths = list(filter(\n",
    "        lambda path: path.split(\".\")[-1] == \"json\", \n",
    "        getContents(base_path, key)\n",
    "    ))\n",
    "    data = getFileData(paths)\n",
    "    for ID, json_data in data.items():\n",
    "        addUpdate(dict_, ID, json_data[0])\n",
    "\n",
    "def updateText(dict_, base_path, key):\n",
    "    paths = getSubContents(base_path, key)\n",
    "    data = getFileData(paths, dataExtractor=lambda file: file.read())\n",
    "    for ID, text in data.items():\n",
    "        addUpdate(dict_, ID, {\"text\": text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1570b6e9-e1f3-4253-92c8-5d22d46a70a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateCollection(obj, collection):\n",
    "    docDoesNotExist = lambda data: collection.count_documents({\"id\": data[\"id\"]}) == 0\n",
    "    for ID in obj:\n",
    "        obj[ID][\"id\"] = ID\n",
    "    filtered = list(filter(docDoesNotExist, [data for data in obj.values()]))\n",
    "    if len(filtered) > 0:\n",
    "        collection.insert_many(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f68949-9d4c-44ba-b446-a4ea2f8ba098",
   "metadata": {},
   "outputs": [],
   "source": [
    "testDocketPath = \"USTR/USTR-2015-0010/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf9577b-0969-49f9-b5b3-2206b0e36dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def storeDocketInfo(docketPath):\n",
    "    base_path =  f\"{docketPath}text-{docketPath.split(\"/\")[-2]}/\"\n",
    "    fields = getSubKeys(base_path, fullKey=False)\n",
    "    bson_comments = {}\n",
    "    bson_documents = {}\n",
    "    bson_docket = {}\n",
    "    if \"comments\" in fields:\n",
    "        updateJson(bson_comments, base_path, \"comments\")\n",
    "    if \"comments_extracted_text\" in fields:\n",
    "        updateText(bson_comments, base_path, \"comments_extracted_text\")\n",
    "        \n",
    "    if \"documents\" in fields:\n",
    "        updateJson(bson_documents, base_path, \"documents\")\n",
    "    if \"documents_extracted_text\" in fields:\n",
    "        updateText(bson_documents, base_path, \"documents_extracted_text\")\n",
    "\n",
    "    if \"docket\" in fields:\n",
    "        updateJson(bson_docket, base_path, \"docket\")\n",
    "    \n",
    "    db = pymongo.MongoClient().mirrulations\n",
    "    updateCollection(bson_comments, db.raw_comments)\n",
    "    updateCollection(bson_documents, db.raw_documents)\n",
    "    updateCollection(bson_docket, db.raw_dockets)\n",
    "\n",
    "storeDocketInfo(testDocketPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8def5cac-63a2-4e4c-9703-15724ec0d4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mp.Pool(4) as pool:\n",
    "    pool.map(storeDocketInfo, dockets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CMSE495-TwoSix",
   "language": "python",
   "name": "cmse495-twosix"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
