{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "943cdad7-d830-4c6c-b756-628441b8c9d8",
   "metadata": {},
   "source": [
    "Please ensure that you are using the CMSE495-TwoSix conda environment (see INSTALL.md), and have a MongoDB server running locally.\n",
    "\n",
    "Prior to running this demo code, please collect some data. To collect a small sample, run the code located in `data_collection/API-Scraping.ipynb`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec850ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00725cf2-9a30-4780-af28-d1cc368a847e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "client = MongoClient()\n",
    "db = client.regulationsgov_test # Testing DB\n",
    "comments_collection = db.comments\n",
    "details_collection = db.details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f3100f-caf6-4779-a814-9a14f8b3428d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import pipeline\n",
    "topic_embedder = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "perspective_model = SentenceTransformer(\"nli-roberta-base-v2\")\n",
    "# comment_perspectives = pipeline(task=\"text2text-generation\", model=\"google/flan-t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b804f03d-06e4-45cf-a013-422bb4422e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_data = [ details[\"comment\"][\"plaintext\"] for details in details_collection.find()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729aa4bf-d1cb-42d2-a8e8-71fcc43c04ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of files in the current working directory, such as â€˜files = os.listdir()\n",
    "\n",
    "files = os.listdir()\n",
    "\n",
    "if \"topic_embeddings.npy\" in files:\n",
    "    topic_embeddings = np.load(\"topic_embeddings.npy\")\n",
    "else:\n",
    "    topic_embeddings = topic_embedder.encode(comment_data,show_progress_bar=True)\n",
    "    np.save(\"topic_embeddings.npy\", topic_embeddings)\n",
    "\n",
    "if \"perspective_embeddings.npy\" in files:\n",
    "    perspective_embeddings = np.load(\"perspective_embeddings.npy\")\n",
    "else:\n",
    "    perspective_embeddings = perspective_model.encode(comment_data,show_progress_bar=True)\n",
    "    np.save(\"perspective_embeddings.npy\", perspective_embeddings)\n",
    "\n",
    "# Concatenate topic + perspective embeddings\n",
    "final_embeddings = np.hstack((topic_embeddings, perspective_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51e1c20-9b88-4faf-acbc-e7b863c11d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# comments variable from API-Scraping.ipynb - please bring that in\n",
    "# Example timestamps (YYYY-MM-DD format)\n",
    "timestamps = pd.to_datetime(comments[\"Posted Date\"]).astype(int) / 10**9  # Convert to Unix timestamps\n",
    "timestamps = timestamps.to_numpy()\n",
    "\n",
    "# Normalize timestamps to [0,1] range\n",
    "scaler = MinMaxScaler()\n",
    "normalized_timestamps = scaler.fit_transform(timestamps.reshape(-1, 1))\n",
    "\n",
    "# Append normalized time to embeddings\n",
    "final_embeddings = np.hstack((final_embeddings, normalized_timestamps))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de422377-8829-4d9b-8a07-84ce366bc626",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import hdbscan\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_embeddings = scaler.fit_transform(topic_embeddings)\n",
    "\n",
    "# Apply HDBSCAN to cluster comments into topics\n",
    "clusterer = hdbscan.HDBSCAN(min_cluster_size=15, metric=\"euclidean\", cluster_selection_method=\"eom\")\n",
    "comments[\"topic_cluster\"] = clusterer.fit_predict(scaled_embeddings)\n",
    "\n",
    "# Count the number of topics\n",
    "num_topics = len(set(comments[\"topic_cluster\"])) - (1 if -1 in comments[\"topic_cluster\"].values else 0)\n",
    "print(f\"Number of Topics Identified: {num_topics}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d85f736-eaf3-4d4e-829c-f92653c2bbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import phate\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Run PHATE\n",
    "phate_operator = phate.PHATE()\n",
    "phate_embedding = phate_operator.fit_transform(final_embeddings)\n",
    "\n",
    "# Visualize\n",
    "plt.scatter(phate_embedding[:, 0], phate_embedding[:, 1], c=normalized_timestamps, cmap=\"viridis\")\n",
    "plt.colorbar(label=\"Time Progression\")\n",
    "plt.title(\"Comment Evolution Over Time\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CMSE495-TwoSix",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "2283f9d377bfc00d15a815433bef4f16278391faa367892d9e17b50238856181"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
