#!/bin/bash --login

#SBATCH --time=06:00:00                 # Job runtime (HH:MM:SS)
#SBATCH --nodes=1                       # Number of nodes to request
#SBATCH --ntasks-per-node=1             # Number of tasks per node
#SBATCH --cpus-per-task=1               # Number of CPU cores per task
#SBATCH --mem-per-cpu=16G               # Memory allocation per CPU core
#SBATCH --job-name=eda_and_basic_model  # Name of the job

#SBATCH --mail-type=ALL                 # Email notifications on all job events (START, END, FAIL, etc.)
#SBATCH --mail-user=tulpulea@msu.edu    # Email to send notifications

#SBATCH --output=%x-%j.SLURMout         # Standard output file: JobName-JobID.SLURMout
#SBATCH --error=%x-%j.SLURMerr          # Standard error file: JobName-JobID.SLURMerr

# Purge all existing modules and load necessary ones
module purge

# Load required modules (example: Python, CUDA, TensorFlow, etc.)
module load python/3.8.10               # Adjust based on your cluster's available modules
module load cuda/11.3                   # If you're using GPU acceleration
module load anaconda/2021.05            # If you're using an Anaconda environment

# Activate a virtual or conda environment (if needed)
source <ENV_NAME>/bin/activate          # Activate conda environment

# Run the Python script
python <SCRIPT_NAME>.py                 # Run script
